# zhihu_scrapy2
抓取知乎个人主页的简单示例

主程序：
scrap_url_zhihu.py

目的：
抓取zhihu用户主页链接，zhihu只允许用户更改一次域名(昵称可以每隔一段时间修改一次)，所以比较稳定。

入口：
选择一名zhihu大V作为入口连接。

数据库：
redis做任务队列，和结果存储。

登陆认证：
在本地使用浏览器登陆后找到相应的cookies.sqlite，程序会解析sqlite并将相应的cookie存到txt中以备登陆使用。

多线程：
多线程从任务队列中获取用户的关注和被关注页面，并解析出所有用户链接，对比已有结果，将新的主页链接存入redis。

其他：
定时统计结果条数，自动生成清理进程脚本。

说明：
本例只是简单示例如何抓取zhihu用户主页链接程序，获取到主页链接后可以根据其他信息如：关注数目，被关注数目，回答，赞，感谢等选项来考量当前用户维度。

需要改进：
zhihu的关注列表超出一屏后需要有webdriver来执行翻页动作(并没有固定页数显示，需要鼠标滚轮一直滚动或鼠标一直指向底部)，这块目前有个初级版本但效果不理想，当条目过多时无法获取到全部信息。
